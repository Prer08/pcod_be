# -*- coding: utf-8 -*-
"""test_mlp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mj7cJspGhu5u_hTiRX9Aq1D4JSdlT-EX
"""

!pip install openpyxl
!pip install imblearn
!pip install opencv-python # Installs the OpenCV library

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score
from torch.utils.data import DataLoader, TensorDataset

from google.colab import drive
drive.mount('/content/drive')

# Define dataset path
new_data_path = "/content/drive/MyDrive/pcos_detection/test.csv"  # Update with the actual dataset path

# Load new dataset
df_new = pd.read_csv(new_data_path)

df_new.head()

"""preprocessing (scalar has deleted copy it from final model for more than 2 row)"""

# Check if the dataset is loaded properly
if df_new.empty:
    raise ValueError("⚠️ The dataset is empty! Please check the file path.")

# 🔹 Step 1: Check missing values before fixing
print("Missing Values Before Fixing:")
print(df_new.isnull().sum())

# 🔹 Step 2: Handle missing values
for col in df_new.columns:
    if df_new[col].dtype == "object":  # For categorical columns
        if df_new[col].nunique() > 0:  # Ensure column has valid values
            df_new[col].fillna(df_new[col].mode()[0], inplace=True)
        else:
            df_new[col].fillna("Unknown", inplace=True)  # Default fill for categorical
    else:  # For numerical columns
        df_new[col] = pd.to_numeric(df_new[col], errors='coerce')  # Ensure correct type
        df_new[col].fillna(df_new[col].median() if df_new.shape[0] > 1 else df_new[col].mean(), inplace=True)

# 🔹 Step 3: Verify missing values are handled
print("\n✅ Missing values handled successfully!")
print(df_new.isnull().sum().sum(), "missing values remaining in the dataset")

"""for more than 2 rows"""

# # Step 1: Standardize column names (Remove extra spaces & unwanted characters)
# df_new.columns = (
#     df_new.columns.str.replace("\s+", " ", regex=True)  # Replace multiple spaces with a single space
#                      .str.strip()  # Remove leading and trailing spaces
#                      .str.replace("I beta-HCG", "beta-HCG", regex=False)  # Fix incorrect column name
# )

# # Step 2: Remove non-informative columns (Sl. No, Patient File No.)
#  df_new.drop(columns=["Sl. No", "Patient File No."], errors='ignore', inplace=True)

# # Step 3: Convert all numerical values to float
# for col in df_new.columns:
#     df_new[col] = pd.to_numeric(df_new[col], errors='coerce')

# # Step 4: Fill NaN values with the median of each column
# df_new.fillna(df_new.median(numeric_only=True), inplace=True)

# # Step 5: Separate features (X) and target variable (y)
# X = df_new.drop(columns=["PCOS (Y/N)"])
# y = df_new["PCOS (Y/N)"]

# # Step 6: Apply Recursive Feature Elimination (RFE) with RandomForestClassifier
# estimator = RandomForestClassifier(random_state=42)
# rfe = RFE(estimator, n_features_to_select=20)  # Select top 20 features
# X_rfe = rfe.fit_transform(X, y)

# # Step 7: Get selected feature names
# selected_features = X.columns[rfe.support_]

# # Convert back to DataFrame
# X_selected = pd.DataFrame(X_rfe, columns=selected_features)

# print("✅ Feature Selection completed successfully!")
# print("Selected Features:", list(selected_features))

from sklearn.feature_selection import RFE
from sklearn.ensemble import RandomForestClassifier


# 🔹 Step 2: Standardize column names
df_new.columns = (
    df_new.columns.str.replace("\s+", " ", regex=True)  # Remove multiple spaces
                   .str.strip()  # Trim spaces
                   .str.replace("I beta-HCG", "beta-HCG", regex=False)  # Fix incorrect column name
)

# 🔹 Step 3: Remove unnecessary columns
df_new.drop(columns=["Sl. No", "Patient File No."], errors="ignore", inplace=True)

# 🔹 Step 4: Convert all numerical values safely
for col in df_new.columns:
    df_new[col] = pd.to_numeric(df_new[col].astype(str).values.ravel(), errors="coerce") # Convert to 1D array

# 🔹 Step 5: Fill missing values with column median
df_new.fillna(df_new.median(numeric_only=True), inplace=True)

# 🔹 Step 6: Use manually selected features
selected_features = [
    'Weight (Kg)', 'Cycle(R/I)', 'Cycle length(days)', 'beta-HCG(mIU/mL)', 'FSH(mIU/mL)',
    'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',
    'Vit D3 (ng/mL)', 'Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)',
    'Fast food (Y/N)', 'Follicle No. (L)', 'Follicle No. (R)', 'Avg. F size (L) (mm)',
    'Avg. F size (R) (mm)'
]

# 🔹 Step 7: Ensure test data has the selected features
X_selected = df_new[selected_features]

print("✅ Feature Selection completed successfully!")
print("Selected Features:", list(selected_features))

df_new.head()

# # Convert 'AMH(ng/mL)' to numeric in both DataFrames
# df_new['AMH(ng/mL)'] = pd.to_numeric(df_new['AMH(ng/mL)'], errors='coerce')

# Correct the column names to match those in the DataFrame
df_new = df_new.drop(columns=["  I   beta-HCG(mIU/mL)", "II    beta-HCG(mIU/mL)"], errors='ignore')
# df_new = df_new.rename(columns={"PCOS (Y/N)": "Target"})

# # --- Limit data to first 541 rows and reset index ---
# df_new = df_new.iloc[:541]
# df_new.reset_index(drop=True, inplace=True)

df_new.info()

columns_to_remove = [
    'Blood Group', 'Pulse rate(bpm)', 'RR (breaths/min)', 'Marraige Status (Yrs)',
    'Pregnant(Y/N)', 'No. of aborptions', 'Ibeta-HCG(mIU/mL)', 'Hip(inch)',
    'Waist(inch)', 'Waist:Hip Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',
    'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)', 'hair growth(Y/N)',
    'Skin darkening (Y/N)', 'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)',
    'Reg.Exercise(Y/N)', 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', 'Follicle No. (L)',
    'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)',
    'Unnamed: 44', 'Sl. No', 'Patient File No.'
]

# Remove only existing columns to avoid errors
df_new = df_new.drop(columns=[col for col in columns_to_remove if col in df_new.columns], errors='ignore')

# Show the cleaned dataset
df_new.head()

"""for more than 2 row

"""

# # Step 1: Check original class distribution
# # Assuming 'PCOS (Y/N)' is your target column in df_new
# y = df_new['PCOS (Y/N)']  # Define y before using it
# print("\n🔍 Class distribution before SMOTE:")
# print(y.value_counts())

# # Step 2: Apply SMOTE for perfect class balancing
# smote = SMOTE(sampling_strategy='auto', random_state=42)  # Auto ensures full balancing
# X_balanced, y_balanced = smote.fit_resample(X_selected.iloc[:, :20], y)  # Ensure 20 selected features are used

# # Step 3: Check new class distribution
# print("\n✅ Class imbalance handled using SMOTE.")
# print("New dataset shape:", X_balanced.shape)
# print("Class distribution after SMOTE:\n", y_balanced.value_counts())

print(f"Model expects {input_dim} features, but X_selected has {X_selected.shape[1]} features.")
print("Selected Features:", selected_features)

# 🔹 Step 2: Convert Entire Dataset to PyTorch Tensor (No "Target" Column)
X_tensor = torch.tensor(df_new.values, dtype=torch.float32)  # No need to drop "Target"

# 🔹 Step 3: Create DataLoader for Testing the Single Sample
batch_size = 1  # Since we have only one row
test_dataset = TensorDataset(X_tensor)  # No target values
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print("✅ Single Sample Ready for Testing! 🚀")

# Define the same MLP model class
torch.manual_seed(42)
class PCOS_MLP(nn.Module):
    def __init__(self, input_dim):
        super(PCOS_MLP, self).__init__()
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.3),

            nn.Linear(64, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3),

            nn.Linear(128, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.3),

            nn.Linear(64, 1),  # Output Layer
            nn.Sigmoid()  # Probability Output
        )

    def forward(self, x):
        return self.mlp(x)

"""for more than 1 row

"""

# import torch
# import numpy as np
# from sklearn.metrics import accuracy_score

# # 🔹 Step 1: Move test data to the appropriate device
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# X_tensor = torch.tensor(X_balanced.values, dtype=torch.float32).to(device)  # Convert entire dataset to tensor

# # 🔹 Step 2: Load the trained model
# model_weights_path = "/content/drive/MyDrive/pcos_detection/MLP_model2.pth"  # Update with actual path
# input_dim = X_balanced.shape[1]  # Ensure correct input dimension
# mlp_model = PCOS_MLP(input_dim).to(device)  # Initialize model with correct input size
# mlp_model.load_state_dict(torch.load(model_weights_path, map_location=device))
# mlp_model.eval()

# # 🔹 Step 3: Perform inference
# with torch.no_grad():
#     y_preds = mlp_model(X_tensor).cpu().numpy().flatten()

# # 🔹 Step 4: Convert predictions to binary labels (Threshold = 0.5)
# predicted_labels = (y_preds >= 0.5).astype(int)

# # 🔹 Step 5: Compute accuracy
# test_accuracy = accuracy_score(y_balanced, predicted_labels)
# print(f'✅ Test Accuracy: {test_accuracy:.4f}')

# # 🔹 Step 6: Save predictions (Optional)
# # Create a new DataFrame with predictions for the balanced dataset
# predictions_df = pd.DataFrame({'Predicted PCOS': predicted_labels}, index=y_balanced.index)

# # Concatenate predictions with original features if needed
# # final_df = pd.concat([X_balanced, predictions_df], axis=1)

# # Save predictions to a CSV file
# predictions_df.to_csv("predictions.csv", index=False)
# print("✅ Predictions saved to predictions.csv")

"""for single row"""

import torch
import numpy as np
from sklearn.metrics import accuracy_score

# 🔹 Step 2: Move test data to the appropriate device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ✅ Ensure X_selected is used and has the correct number of features:
X_tensor = torch.tensor(X_selected[selected_features].values, dtype=torch.float32).to(device) # Use all selected features

# 🔹 Step 3: Load the trained model
model_weights_path = "/content/drive/MyDrive/pcos_detection/MLP_model2.pth"  # Update path
input_dim = 20  # ✅ Set to 20 to match the saved model's input size
mlp_model = PCOS_MLP(input_dim).to(device)  # Initialize model
mlp_model.load_state_dict(torch.load(model_weights_path, map_location=device))
mlp_model.eval()

# 🔹 Step 4: Perform inference
with torch.no_grad():
    # Select the correct number of features before passing to the model
    y_pred = mlp_model(X_tensor[:, :input_dim]).cpu().item()  # Get scalar output

# 🔹 Step 5: Convert prediction to binary label (Threshold = 0.5)
predicted_label = int(y_pred >= 0.5)  # Apply threshold

# 🔹 Step 6: Save Predictions (Optional)
predictions_df = pd.DataFrame({'Predicted PCOS': [predicted_label]})
# predictions_df.to_csv("/content/drive/MyDrive/pcos_detection/prediction_result.csv", index=False)

# 🔹 Step 7: Print Result
pcos_result = "PCOS Detected" if predicted_label == 1 else "No PCOS"
print(f"🔍 Model Prediction: {pcos_result} ✅")