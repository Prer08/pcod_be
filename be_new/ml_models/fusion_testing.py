# -*- coding: utf-8 -*-
"""fusion_testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G-CkXkaydh6uzgEuBI0_LLGE5O0ZlOiM
"""

!pip install openpyxl
!pip install imblearn
!pip install opencv-python # Installs the OpenCV library

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import RFE, mutual_info_classif

import cv2
from PIL import Image

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset, Dataset
import torchvision.models as models
import torch.optim as optim
from torchvision import transforms

from imblearn.over_sampling import SMOTE

import os
import warnings
warnings.filterwarnings("ignore")

import torch
import numpy as np
import cv2
from PIL import Image
import torchvision.transforms as transforms

def preprocess_single_image(image_path, transform=None, augment=False):
    """
    Preprocess a single image using Watershed Segmentation, Multilevel Thresholding, and transformations.

    Args:
        image_path (str): Path to the image file.
        transform (torchvision.transforms.Compose, optional): Transformations to apply.
        augment (bool, optional): Whether to apply augmentation.

    Returns:
        torch.Tensor: Processed image tensor.
    """
    # Load and convert image to RGB
    image = Image.open(image_path).convert("RGB")
    image_np = np.array(image)

    # Apply Watershed Segmentation
    image_segmented = apply_watershed(image_np)

    # Apply Multilevel Thresholding
    image_segmented = apply_multilevel_thresholding(image_segmented)

    # Convert back to PIL Image
    image_segmented = Image.fromarray(image_segmented)

    # Define basic transformations (resize and convert to tensor)
    if transform is None:
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    # Define augmentation transforms if enabled
    augmentation_transform = transforms.Compose([
        transforms.RandomRotation(degrees=30),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    ]) if augment else None

    # Apply augmentation if enabled
    if augment:
        image_segmented = augmentation_transform(image_segmented)

    # Apply final transformations
    image_tensor = transform(image_segmented)

    return image_tensor

def apply_watershed(image):
    """
    Apply Watershed Segmentation to an image.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    kernel = np.ones((3, 3), np.uint8)
    sure_bg = cv2.dilate(thresh, kernel, iterations=3)
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0
    image_segmented = image.copy()
    cv2.watershed(image_segmented, markers)
    image_segmented[markers == -1] = [255, 0, 0]  # Mark boundaries in red
    return image_segmented

def apply_multilevel_thresholding(image):
    """
    Apply Multilevel Thresholding to detect cysts.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, threshold_1 = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
    _, threshold_2 = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    segmented_image = np.zeros_like(gray)
    segmented_image[threshold_1 == 255] = 1
    segmented_image[threshold_2 == 255] = 2
    segmented_image_rgb = cv2.applyColorMap(segmented_image * 85, cv2.COLORMAP_JET)
    return segmented_image_rgb

image_path = "/content/drive/My Drive/pcos_detection/test1/4.jpg"

processed_image = preprocess_single_image(image_path, augment=True)

# Display the processed image shape
print(processed_image.shape)  # Should be [3, 224, 224]

import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import StandardScaler

def preprocess_pcos_test_data(csv_file, selected_features):
    df = pd.read_csv(csv_file)

    # âœ… Standardize column names
    df.columns = (df.columns.str.replace("\s+", " ", regex=True)
                              .str.strip()
                              .str.replace("I beta-HCG", "beta-HCG", regex=False))

    # âœ… Drop unnecessary and non-informative columns
    columns_to_remove = [
        'Sl. No', 'Patient File No.', 'Blood Group', 'Pulse rate(bpm)', 'RR (breaths/min)',
        'Marraige Status (Yrs)', 'Pregnant(Y/N)', 'No. of abortions', 'Ibeta-HCG(mIU/mL)',
        'Hip(inch)', 'Waist(inch)', 'Waist:Hip Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',
        'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)', 'hair growth(Y/N)',
         'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)',
        'Reg.Exercise(Y/N)', 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)', 'Follicle No. (L)',
        'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'Endometrium (mm)',
        'PCOS (Y/N)'  # âŒ Remove target column (not available in test data)
    ]
    df.drop(columns=columns_to_remove, errors='ignore', inplace=True)

    # âœ… Convert numerical values to float
    for col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    # âœ… Handle missing values
    for col in df.columns:
        if df[col].dtype == "object":
            df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical with mode
        else:
            df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median

    # âœ… Feature Scaling (Z-score normalization)
    # scaler = StandardScaler()
    # df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

    # âœ… Select only features used in training
    df = df[selected_features]
    print(df.head())
    # âœ… Convert to PyTorch tensor
    tab_features = torch.tensor(df.values.astype(np.float32))

    return tab_features

# Example usage:
csv_file = "/content/drive/My Drive/pcos_detection/test.csv"
selected_features = ['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Hb(g/dl)',
        'Cycle(R/I)', 'Cycle length(days)', 'beta-HCG(mIU/mL)',
        'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH']  # Provide the selected features from training

# âœ… Preprocess Test Data
tabular_features = preprocess_pcos_test_data(csv_file, selected_features)

print("Test Data Shape:", tabular_features.shape)

import torch
import torch.nn as nn
import torchvision.models as models

class PCOS_MLP(nn.Module):
    def __init__(self, input_dim):
        super(PCOS_MLP, self).__init__()
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.3),

            nn.Linear(64, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3),

            nn.Linear(128, 64),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            nn.Dropout(0.3),

            nn.Linear(64, 32),  # Output Layer for tabular data
            nn.Sigmoid()  # Probability Output for binary classification
        )

    def forward(self, x):
        return self.mlp(x)  # Expected output shape: [batch_size, 1]

class PCOS_CNN(nn.Module):
    def __init__(self, num_classes=2):
        super(PCOS_CNN, self).__init__()
        self.cnn = models.resnet18(pretrained=True)  # Use ResNet18 as the backbone
        self.cnn.fc = nn.Linear(512, 32)  # Modify the last layer to output a 32D feature vector

        self.classifier = nn.Sequential(
            nn.Linear(32, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3),
            nn.Linear(128, 512)  # Final output layer for classification
        )

    def forward(self, x):
        x = self.cnn(x)  # Extract image features (Shape: [batch_size, 32])
        return x  # Returning 32D features


class PCOS_Multimodal(nn.Module):
    def __init__(self, tabular_input_dim, num_classes=2):
        super(PCOS_Multimodal, self).__init__()
        self.mlp_model = PCOS_MLP(tabular_input_dim)
        self.cnn_model = PCOS_CNN(num_classes)

        # Final classifier to combine both the outputs
        self.fc = nn.Sequential(
            nn.Linear(32 + 32, 128),  # 1 from MLP output and 32 from CNN output
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes),  # Final output layer for classification
            nn.Softmax(dim=1)  # Output class probabilities
        )

    def forward(self, tabular_input, image_input):
        # Process the tabular data through the MLP model
        mlp_output = self.mlp_model(tabular_input)  # Shape: [batch_size, 1]
        # print(f"MLP Output Shape: {mlp_output.shape}")

        # Process the image data through the CNN model
        cnn_output = self.cnn_model(image_input)  # Shape: [batch_size, num_classes]
        # print(f"CNN Output Shape: {cnn_output.shape}")

        # Concatenate the outputs of both models (MLP and CNN)
        combined_input = torch.cat((mlp_output, cnn_output), dim=1)  # Concatenate along the feature dimension
        # print(f"Combined Input Shape: {combined_input.shape}")

        # Pass through the final classifier
        output = self.fc(combined_input)
        return output

print(processed_image.shape)
print(tabular_features.shape)
print(tabular_features)

# Model class must be defined somewhere
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

image_input = processed_image.unsqueeze(0).to(device)  # This converts the shape to [1, 3, 224, 224]

# âœ… Correctly reshape tabular data for the MLP model
tabular_input = tabular_features.to(device)  # âœ… Remove unsqueeze(0) to keep shape [1, 12]

PATH="/content/drive/My Drive/pcos_detection/multimodal_model_final.pth"

# ğŸ”¹ Define Model Parameters

num_classes = 2  # Binary classification (PCOS or not)

# âœ… Change this to 12 to match the saved model's input size:
tabular_input_dim = 11

# Initialize Model with the correct tabular_input_dim
model = PCOS_Multimodal(tabular_input_dim, num_classes).to(device)
print("âœ… Multimodel Ready! ğŸš€")

# 2. Load the state dictionary into the model
state_dict = torch.load(PATH)
model.load_state_dict(state_dict)

# Now you can call model.eval()
model.eval()

# Run the model on the test case (image and tabular data)
with torch.no_grad():
    output = model(tabular_input, image_input)

# ğŸ”¹ Step 5: Convert prediction to binary label (Threshold = 0.5)
predicted_label = (output.argmax(dim=1) >= 0.5).int().item()  # Apply threshold

# ğŸ”¹ Step 6: Save Predictions (Optional)
predictions_df = pd.DataFrame({'Predicted PCOS': [predicted_label]})

# Print the output
print("Model Output (Class Probabilities):", output)
pcos_result = "PCOS Detected" if predicted_label == 1 else "No PCOS"
print(f"ğŸ” Model Prediction: {pcos_result} âœ…")