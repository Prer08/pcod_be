# -*- coding: utf-8 -*-
"""CNN_TESTING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AVWaGtOpC1E93pT-jnIZ1-95TvRC0Kvr
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset, Dataset
import torchvision.models as models
import torch.optim as optim
from torchvision import transforms

import pandas as pd

"""for testing file(not single image)"""

# import os
# from PIL import Image
# import numpy as np
# import cv2  # OpenCV for image processing
# from torch.utils.data import Dataset
# from torchvision import transforms

# class PCOSImageDataset(Dataset):
#     def __init__(self, image_folder, transform=None, augment=True):
#         self.image_paths = []
#         self.labels = []
#         class_mapping = {"notinfected": 0, "infected": 1}

#         for class_name in os.listdir(image_folder):
#             class_path = os.path.join(image_folder, class_name)
#             if os.path.isdir(class_path):  # Ensure it's a directory
#                 for img_name in os.listdir(class_path):
#                     img_path = os.path.join(class_path, img_name)
#                     # Only load valid image formats
#                     if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):
#                         self.image_paths.append(img_path)
#                         self.labels.append(class_mapping[class_name])  # Assign label based on folder name

#         # Data Augmentation transforms (if augment is True)
#         self.augment = augment

#         self.transform = transforms.Compose([
#             transforms.Resize((224, 224)),  # Resize images to 224x224
#             transforms.ToTensor(),  # Convert images to tensor
#         ]) if transform is None else transform  # Use provided transform if any

#         # Augmentation transformations
#         self.augmentation_transform = transforms.Compose([
#             transforms.RandomRotation(degrees=30),  # Random Rotation (-30 to 30 degrees)
#             transforms.RandomHorizontalFlip(),  # Random horizontal flip
#             transforms.RandomVerticalFlip(),  # Random vertical flip
#             transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Zooming, crop with random scaling
#             transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Brightness adjustments
#         ]) if augment else None

#     def __len__(self):
#         return len(self.image_paths)

#     def __getitem__(self, idx):
#         img_path = self.image_paths[idx]
#         image = Image.open(img_path).convert("RGB")  # Convert image to RGB

#         # Convert to numpy array for processing
#         image_np = np.array(image)

#         # Apply Watershed Segmentation
#         image_segmented = self.apply_watershed(image_np)

#         # Apply Multilevel Thresholding to detect cysts
#         image_segmented = self.apply_multilevel_thresholding(image_segmented)

#         # Convert back to PIL Image
#         image_segmented = Image.fromarray(image_segmented)

#         # Apply Augmentation if enabled
#         if self.augment:
#             image_segmented = self.augmentation_transform(image_segmented)  # Apply augmentation

#         # Apply basic transformations (resize + tensor conversion)
#         image_segmented = self.transform(image_segmented)

#         label = self.labels[idx]
#         return image_segmented, label

#     def apply_watershed(self, image):
#         """
#         Apply Watershed Segmentation to the image.
#         This method detects the follicle boundaries based on intensity changes.
#         """
#         # Step 1: Convert to grayscale
#         gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

#         # Step 2: Apply thresholding to get a binary image (foreground vs background)
#         _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

#         # Step 3: Remove noise using morphological operations
#         kernel = np.ones((3, 3), np.uint8)
#         sure_bg = cv2.dilate(thresh, kernel, iterations=3)

#         # Step 4: Apply distance transform
#         dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
#         _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

#         # Step 5: Subtract sure foreground from sure background to get unknown region
#         sure_fg = np.uint8(sure_fg)
#         unknown = cv2.subtract(sure_bg, sure_fg)

#         # Step 6: Label markers (foreground vs background)
#         _, markers = cv2.connectedComponents(sure_fg)

#         # Step 7: Apply watershed algorithm
#         markers = markers + 1
#         markers[unknown == 255] = 0

#         # Step 8: Perform watershed algorithm
#         image_segmented = image.copy()
#         cv2.watershed(image_segmented, markers)

#         # Mark boundary pixels
#         image_segmented[markers == -1] = [255, 0, 0]  # Red boundary lines

#         return image_segmented

#     def apply_multilevel_thresholding(self, image):
#         """
#         Apply Multilevel Thresholding to detect cysts.
#         This method identifies cysts by using multiple thresholds.
#         """
#         gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

#         # Use Otsu's method for automatic thresholding, or you can manually choose threshold values
#         _, threshold_1 = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
#         _, threshold_2 = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)

#         # Combine multiple thresholds to create segmented regions
#         segmented_image = np.zeros_like(gray)
#         segmented_image[threshold_1 == 255] = 1  # Cyst regions marked as 1
#         segmented_image[threshold_2 == 255] = 2  # Follicle regions marked as 2

#         # Convert back to RGB for visualization
#         segmented_image_rgb = cv2.applyColorMap(segmented_image * 85, cv2.COLORMAP_JET)  # Colorize the output
#         return segmented_image_rgb

import torch
import numpy as np
import cv2
from PIL import Image
import torchvision.transforms as transforms

def preprocess_single_image(image_path, transform=None, augment=False):
    """
    Preprocess a single image using Watershed Segmentation, Multilevel Thresholding, and transformations.

    Args:
        image_path (str): Path to the image file.
        transform (torchvision.transforms.Compose, optional): Transformations to apply.
        augment (bool, optional): Whether to apply augmentation.

    Returns:
        torch.Tensor: Processed image tensor.
    """
    # Load and convert image to RGB
    image = Image.open(image_path).convert("RGB")
    image_np = np.array(image)

    # Apply Watershed Segmentation
    image_segmented = apply_watershed(image_np)

    # Apply Multilevel Thresholding
    image_segmented = apply_multilevel_thresholding(image_segmented)

    # Convert back to PIL Image
    image_segmented = Image.fromarray(image_segmented)

    # Define basic transformations (resize and convert to tensor)
    if transform is None:
        transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    # Define augmentation transforms if enabled
    augmentation_transform = transforms.Compose([
        transforms.RandomRotation(degrees=30),
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    ]) if augment else None

    # Apply augmentation if enabled
    if augment:
        image_segmented = augmentation_transform(image_segmented)

    # Apply final transformations
    image_tensor = transform(image_segmented)

    return image_tensor

def apply_watershed(image):
    """
    Apply Watershed Segmentation to an image.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    kernel = np.ones((3, 3), np.uint8)
    sure_bg = cv2.dilate(thresh, kernel, iterations=3)
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0
    image_segmented = image.copy()
    cv2.watershed(image_segmented, markers)
    image_segmented[markers == -1] = [255, 0, 0]  # Mark boundaries in red
    return image_segmented

def apply_multilevel_thresholding(image):
    """
    Apply Multilevel Thresholding to detect cysts.
    """
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, threshold_1 = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
    _, threshold_2 = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    segmented_image = np.zeros_like(gray)
    segmented_image[threshold_1 == 255] = 1
    segmented_image[threshold_2 == 255] = 2
    segmented_image_rgb = cv2.applyColorMap(segmented_image * 85, cv2.COLORMAP_JET)
    return segmented_image_rgb

# 🔹 CNN Model for Ultrasound Images
class PCOS_CNN(nn.Module):
    def __init__(self, num_classes=2):
        super(PCOS_CNN, self).__init__()
        self.cnn = models.resnet18(pretrained=True)  # Use ResNet18 as the backbone
        self.cnn.fc = nn.Linear(512, 32)  # Modify the last layer to output a 32D feature vector

        self.classifier = nn.Sequential(
            nn.Linear(32, 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)  # Final classification layer
        )

    def forward(self, x):
        x = self.cnn(x)  # Extract image features
        x = self.classifier(x)  # Pass through the classifier
        return x

# Model class must be defined somewhere
PATH="/content/drive/My Drive/pcos_detection/cnn_model.pth"


# 🔹 Define Model Parameters
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_classes = 2  # Binary classification (PCOS or not)

# Initialize Model
model = PCOS_CNN(num_classes).to(device)
print("✅ CNN Model for Ultrasound Images Ready! 🚀")

# 2. Load the state dictionary into the model
state_dict = torch.load(PATH)
model.load_state_dict(state_dict)

# Now you can call model.eval()
model.eval()

# # 🔹 Define Paths to Image Datasets
# # train_image_folder = "/content/drive/My Drive/pcos_detection/train/"
# test_image_folder = "/content/drive/My Drive/pcos_detection/test1/1.jpg"

# # 🔹 Load Image Datasets (Now handles corrupt images)
# # train_image_dataset = PCOSImageDataset(train_image_folder)
# test_image_dataset = PCOSImageDataset(test_image_folder)

# # train_loader = DataLoader(train_image_dataset, batch_size=32, shuffle=True)
# test_loader = DataLoader(test_image_dataset, batch_size=32, shuffle=False)

# print("✅ Image Dataset Loaded Correctly! 🚀")

image_path = "/content/drive/My Drive/pcos_detection/test1/2.jpg"

test_image_dataset = preprocess_single_image(image_path, augment=True)

# Reshape the tensor to add a batch dimension
test_image_dataset = test_image_dataset.unsqueeze(0) # Add a dimension at the beginning for the batch size

# Display the processed image shape
print(test_image_dataset.shape)  # Should be [1, 3, 224, 224]

print(len(test_image_dataset))

# Run the model on the test case (image and tabular data)
with torch.no_grad():
    output = model(test_image_dataset)

# 🔹 Step 5: Convert prediction to binary label (Threshold = 0.5)
# Get the predicted class index (0 or 1)
predicted_class_index = torch.argmax(output, dim=1).item()

# Convert the class index to a binary label (0 or 1) based on your threshold
predicted_label = 1 if predicted_class_index == 1 else 0 # Assuming class 1 represents PCOS

# 🔹 Step 6: Save Predictions (Optional)
predictions_df = pd.DataFrame({'Predicted PCOS': [predicted_label]})

# Print the output
print("Model Output (Class Probabilities):", output)
pcos_result = "PCOS Detected" if predicted_label == 1 else "No PCOS"
print(f"🔍 Model Prediction: {pcos_result} ✅")

# criterion = nn.CrossEntropyLoss()
# total_val_loss = 0.0
# correct_val = 0
# total_val = 0

# with torch.no_grad():
#     for images, labels in test_loader:
#         images, labels = images.to(device), labels.to(device)
#         outputs = model(images)
#         loss = criterion(outputs, labels)

#         total_val_loss += loss.item() * images.size(0)  # Sum loss for batch
#         _, predicted = torch.max(outputs, 1)
#         correct_val += (predicted == labels).sum().item()
#         total_val += labels.size(0)

# val_loss = total_val_loss / total_val  # Compute average loss
# val_accuracy = 100 * correct_val / total_val
# print(val_accuracy)